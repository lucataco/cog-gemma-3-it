# Configuration for Cog ⚙️
# Reference: https://cog.run/yaml

build:
  # Gemma 3 requires a GPU
  gpu: true
  cuda: "12.1"
  # python version in the form '3.11' or '3.11.4'
  python_version: "3.11"
  python_packages:
    - "torch==2.2.0"
    - "git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3"
    - "accelerate==0.28.0"
    - "pillow==10.2.0"
    - "safetensors==0.4.2"
    - "sentencepiece==0.1.99"
    - "protobuf==4.25.3"
    - "numpy<2"
    - "huggingface-hub"

  # commands to run after the environment is setup
  run:
    - curl -o /usr/local/bin/pget -L "https://github.com/replicate/pget/releases/download/v0.8.2/pget_linux_x86_64" && chmod +x /usr/local/bin/pget

# predict.py defines how predictions are run on your model
predict: "predict.py:Predictor"
